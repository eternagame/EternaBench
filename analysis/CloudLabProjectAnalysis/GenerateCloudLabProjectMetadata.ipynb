{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0c64736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%pylab inline\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style('ticks')\n",
    "sns.set_context('paper')\n",
    "\n",
    "import eternabench as eb\n",
    "from RiboGraphViz import RGV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f37b859",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(os.environ['ETERNABENCH_PATH']+'/data/EternaBench_ChemMapping_Full_10Jul2021.json.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96eb1080",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['GC content'] = [(x.count('G')+x.count('C'))/len(x) for x in df['sequence']]\n",
    "df['Length'] = [len(x)-21 for x in df['sequence']]\n",
    "df['signal_to_noise'] = [float(x.split(':')[-1]) for x in df['signal_to_noise']]\n",
    "df['Max. reactivity'] = df.apply(lambda row: np.max(row['reactivity']), axis=1)\n",
    "df['Median reactivity'] = df.apply(lambda row: np.median(row['reactivity']), axis=1)\n",
    "\n",
    "def get_RGV_stats(row):\n",
    "    try:\n",
    "        mdl = RGV(row['structure'])\n",
    "        mdl.run_structure_properties()\n",
    "        loop_count = len(list([x for x in mdl.G.nodes if isinstance(x, int)]))-1\n",
    "        return loop_count, np.clip(mdl.n_hairpins,0,100), mdl.n_internal_loops, mdl.n_3WJs + mdl.n_4WJs+ mdl.n_5WJs_up\n",
    "    except:\n",
    "        struct = row['structure'].replace('))(((((((....))))))).....................','..(((((((....))))))).....................')\n",
    "        mdl = RGV(struct)\n",
    "        mdl.run_structure_properties()\n",
    "        loop_count = len(list([x for x in mdl.G.nodes if isinstance(x, int)]))-1\n",
    "        return loop_count, np.clip(mdl.n_hairpins,0,100), mdl.n_internal_loops, mdl.n_3WJs + mdl.n_4WJs + mdl.n_5WJs_up\n",
    "    \n",
    "unique_struct_df = pd.DataFrame({'structure': [x for x in set(df.structure)]}) \n",
    "unique_struct_df[['Target structure, total loops', 'Target structure, # hairpins','Target structure, # Internal loops','Target structure, # Multiloops']] =\\\n",
    "unique_struct_df.apply(lambda row: get_RGV_stats(row), axis=1, result_type='expand')\n",
    "df = df.merge(unique_struct_df, on='structure')\n",
    "\n",
    "df.to_json('CloudLabMetadata.json.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6cbf647c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21864\n",
      "13583\n"
     ]
    }
   ],
   "source": [
    "project_scores = pd.read_csv(os.environ['ETERNABENCH_PATH']+'/scoring_data/EB_projects_-efold_pearson_zscores_by_project_name.csv')\n",
    "print(len(project_scores))\n",
    "project_scores = project_scores.loc[project_scores.pearson_std<0.05]\n",
    "print(len(project_scores))\n",
    "\n",
    "project_variance = project_scores.groupby(['project_name'])['pearson_mean'].std()\n",
    "project_variance = project_variance.reset_index()\n",
    "project_variance['Stddev_of_package_correlations'] = project_variance['pearson_mean']\n",
    "project_variance = project_variance.drop(columns=['pearson_mean'])\n",
    "\n",
    "\n",
    "project_mean = project_scores.groupby(['project_name'])['pearson_mean'].mean()\n",
    "project_mean = project_mean.reset_index()\n",
    "project_mean['Mean_of_package_correlations'] = project_mean['pearson_mean']\n",
    "project_mean = project_mean.drop(columns=['pearson_mean'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9ff2226",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_project_stats(df):\n",
    "    project_stats = df.groupby(['Dataset','project_name']).mean()\n",
    "    project_sizes = df.groupby(['Dataset','project_name'])['sequence'].size()\n",
    "\n",
    "    project_sizes = project_sizes.reset_index()\n",
    "    project_stats = project_stats.reset_index()\n",
    "    project_stats['# constructs'] = project_sizes['sequence']\n",
    "    project_stats = project_stats.loc[~project_stats.Dataset.isna()]\n",
    "    project_stats = project_stats.loc[project_stats.Dataset!='RYOS_I']\n",
    "    \n",
    "    proj_entropies = pd.DataFrame()\n",
    "    for proj_name in df.project_name.unique():\n",
    "        if proj_name is not None:\n",
    "            seqs = [x for x in df.loc[df.project_name==proj_name]['sequence']]\n",
    "            n_lengths = len(list(set([len(x) for x in seqs])))\n",
    "            if n_lengths == 1:\n",
    "                entropy = eb.sequence_analysis.positional_entropy(seqs)\n",
    "                proj_entropies = proj_entropies.append({'project_name': proj_name, 'Sequence Entropy': entropy/np.log(4)}, ignore_index=True)\n",
    "\n",
    "    project_stats = project_stats.merge(proj_entropies, on='project_name',how='left')\n",
    "    return project_stats\n",
    "\n",
    "proj_stats = create_project_stats(df)\n",
    "proj_stats_filt = create_project_stats(df.loc[df.passed_CDHIT_filter==True])\n",
    "proj_stats_filt = proj_stats_filt.merge(project_mean,on='project_name',how='left')\n",
    "proj_stats_filt = proj_stats_filt.merge(project_variance,on='project_name',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e09b61fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfold_zscores = project_scores.loc[project_scores.package=='contrafold_2']\n",
    "cfold_zscores['cfold_zscore'] = cfold_zscores['pearson_zscore_by_project_name_mean']\n",
    "cfold_zscores = cfold_zscores[['project_name', 'cfold_zscore']]\n",
    "proj_stats_filt = proj_stats_filt.merge(cfold_zscores, on='project_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc7d3d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_stats.to_json('~/das/github/EternaBench/analysis/proj_stats.json.zip')\n",
    "proj_stats_filt.to_json('~/das/github/EternaBench/analysis/proj_stats_filt.json.zip')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
